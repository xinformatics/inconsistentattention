{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ad3a29d-9141-4f40-89e9-2926468d7e54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcfb55dd-1ab2-4c2f-8f20-63916649f652",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, confusion_matrix, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a32444e-3648-47c6-8da2-518b579874b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8150ade-f73a-4b13-bb12-1d32b4182aab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# seed=42\n",
    "# reproducible = True\n",
    "# # Setting the seed before gin parsing\n",
    "# os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "# random.seed(seed)\n",
    "# np.random.seed(seed)\n",
    "# torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed_all(seed)  # For multi-GPU setups\n",
    "\n",
    "# if reproducible:\n",
    "#     os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "#     torch.use_deterministic_algorithms(True)\n",
    "#     torch.backends.cudnn.deterministic = True\n",
    "#     torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644ab91b-5ee4-40fd-b2bd-a758816a6eb2",
   "metadata": {},
   "source": [
    "# get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8600c095-361e-4f02-8a71-54229ac8690d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TorchDataset(Dataset):\n",
    "    def __init__(self, data_path, labels_path):\n",
    "        self.data = torch.load(data_path)\n",
    "        self.labels = torch.load(labels_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data[idx]\n",
    "        labels = self.labels[idx]\n",
    "        # return torch.tensor(data, dtype=torch.float32), torch.tensor(labels, dtype=torch.float32)\n",
    "        return data.clone().detach(), labels.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5973dfeb-633f-42a1-8720-fa00fb3d366e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example usage for creating datasets\n",
    "train_dataset = TorchDataset('Phenotyping/Ptrain.pt', 'Phenotyping/y_train.pt')\n",
    "valid_dataset = TorchDataset('Phenotyping/Pvalid.pt', 'Phenotyping/y_valid.pt')\n",
    "test_dataset  = TorchDataset('Phenotyping/Ptest.pt', 'Phenotyping/y_test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bb9f6a1-cf3a-4826-ba56-0de7c1a7f79e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=1, pin_memory=True, prefetch_factor=2)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=256, shuffle=False, num_workers=1, pin_memory=True, prefetch_factor=2)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=256, shuffle=False, num_workers=1, pin_memory=True, prefetch_factor=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73afcbf5-d796-4923-acbf-725a826c52e9",
   "metadata": {},
   "source": [
    "## model as in Gandin, Ilaria, et al. \"Interpretability of time-series deep learning models: A study in cardiovascular patients admitted to Intensive care unit.\" Journal of biomedical informatics 121 (2021): 103876."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcc2b493-80de-4af2-a928-f8732270f67d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the Attention Layer\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attention_dense = nn.Linear(shape, shape)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # Apply linear transformation\n",
    "        a = self.attention_dense(inputs)\n",
    "        # Apply softmax to get attention scores\n",
    "        attention_scores = torch.softmax(a, dim=-1)\n",
    "        # Element-wise multiplication with inputs\n",
    "        output_attention_mul = inputs * attention_scores\n",
    "        return output_attention_mul, attention_scores\n",
    "\n",
    "# Define the Model\n",
    "class CustomModel_attext(nn.Module):\n",
    "    def __init__(self, n_wind, n_features, dense_nparams1=256, n_classes=15):  # n_classes is added\n",
    "        super(CustomModel_attext, self).__init__()\n",
    "        self.attention = Attention(n_features)\n",
    "        self.lstm = nn.LSTM(n_features, dense_nparams1, num_layers=1, batch_first=True)\n",
    "        self.dense = nn.Linear(dense_nparams1, n_classes)  # Output layer now has n_classes outputs\n",
    "    \n",
    "    def forward(self, x, return_attention=False):\n",
    "        # Get the attended output and attention scores\n",
    "        x, attention_scores = self.attention(x)\n",
    "        # Pass through LSTM\n",
    "        x, _ = self.lstm(x)\n",
    "        # Extract the last output of the LSTM\n",
    "        x = x[:, -1, :]\n",
    "        # Apply the dense layer to get logits (no softmax)\n",
    "        logits = self.dense(x)\n",
    "        \n",
    "        if return_attention:\n",
    "            return logits, attention_scores\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7eb5e31f-c6a9-4672-a51e-ab59fe6227b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca55220f-31a9-45d4-8b95-0b518c2ed24d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = CustomModel_attext(288, 231, 15)\n",
    "criterion = criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0a78c05-534f-4892-87db-575cc6dc72e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(train_loader, model, criterion, optimizer, device):\n",
    "    output_list = []\n",
    "    target_list = [] \n",
    "    # Switch to train mode\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    for count, (data, label) in enumerate(train_loader):\n",
    "        # Move data and labels to the specified device (GPU/CPU)\n",
    "        data = data.to(device).type(torch.float)\n",
    "        label = label.to(device).type(torch.long)  # Ensure labels are long type\n",
    "\n",
    "        # Debugging prints\n",
    "        # print(f\"Batch {count} - Label unique values: {torch.unique(label)}\")\n",
    "\n",
    "        # Compute output (logits from the model)\n",
    "        output = model(data)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        # Convert output and target to lists for tracking\n",
    "        output_np = output.argmax(dim=1).detach().cpu().numpy().tolist()  # Get predicted class indices\n",
    "        target_np = label.detach().cpu().numpy().tolist()\n",
    "        output_list += output_np\n",
    "        target_list += target_np\n",
    "\n",
    "        # Compute gradient and do an optimizer step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return output_list, target_list\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion, device):\n",
    "    output_list = []\n",
    "    target_list = [] \n",
    "    # Switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for count, (data, label) in enumerate(val_loader):\n",
    "            # Move data and labels to the specified device (GPU/CPU)\n",
    "            data = data.to(device).type(torch.float)\n",
    "            label = label.to(device).type(torch.long)  # Ensure labels are long type\n",
    "\n",
    "            # Debugging prints\n",
    "            # print(f\"Batch {count} - Label unique values: {torch.unique(label)}\")\n",
    "\n",
    "            # Compute output (logits from the model)\n",
    "            output = model(data)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = criterion(output, label)\n",
    "\n",
    "            # Convert output and target to lists for tracking\n",
    "            output_np = output.argmax(dim=1).detach().cpu().numpy().tolist()  # Get predicted class indices\n",
    "            target_np = label.detach().cpu().numpy().tolist()\n",
    "            output_list += output_np\n",
    "            target_list += target_np\n",
    "\n",
    "    return output_list, target_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d852b092-46a6-42af-a6f8-b1c207fad839",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming you have a variable `seed` already defined\n",
    "model_save_dir = './model_checkpoints/'  # Directory to save models\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(model_save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa5cba7-2d0b-450f-ba1a-18a7e24e17e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in tqdm(range(1000)):\n",
    "    \n",
    "    seed = i\n",
    "    reproducible = True\n",
    "    # Setting the seed before gin parsing\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # For multi-GPU setups\n",
    "\n",
    "    if reproducible:\n",
    "        os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    epoch_list = [] \n",
    "    bal_acc_train = []\n",
    "    bal_acc_val = []\n",
    "    best_bal_acc = 0\n",
    "\n",
    "    model = CustomModel_attext(288, 231, 15)\n",
    "    criterion = criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-6)\n",
    "    \n",
    "    print(f'Starting training for seed {seed}')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_list.append(epoch)\n",
    "\n",
    "        # Train for one epoch\n",
    "        output_train_per, target_train_per = train(train_loader, model, criterion, optimizer, device)\n",
    "\n",
    "        # Calculate balanced accuracy for training data\n",
    "        balanced_acc_train = balanced_accuracy_score(target_train_per, output_train_per)\n",
    "        bal_acc_train += [balanced_acc_train]\n",
    "\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        output_val_per, target_val_per = validate(test_loader, model, criterion, device)\n",
    "\n",
    "        # Calculate balanced accuracy for validation data\n",
    "        balanced_acc_val = balanced_accuracy_score(target_val_per, output_val_per)\n",
    "        bal_acc_val += [balanced_acc_val]\n",
    "\n",
    "        # Update the best balanced accuracy\n",
    "        if balanced_acc_val > best_bal_acc:\n",
    "            best_bal_acc = balanced_acc_val\n",
    "            torch.save(model.state_dict(), os.path.join(model_save_dir, f'bm_bal_acc_seed_{seed:03d}.pth'))\n",
    "\n",
    "            \n",
    "    print(f'Completed training and model saving for seed {seed}')\n",
    "\n",
    "    del model\n",
    "    # collect cache\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
